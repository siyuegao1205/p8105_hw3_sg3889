---
title: "P8105 Homework 3"
author: "Siyue Gao"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
library(p8105.datasets)
```


# Problem 1

## Load the data

```{r}
data("instacart")
```

## Data Description

The `instacart` dataset contains `r nrow(instacart)` observations of `r n_distinct(instacart$user_id)` unique users from the "train" evaluation set, with `r ncol(instacart)` variables, primarily describing information about Instacart online order usage. Some key variables in the dataset are as follows:

*   `user_id`: user identifier
*   `product_id` and `product_name`: product identifier and name of the product, respectively
*   `aisle_id` and `aisle`: aisle identifier and name of the aisle, respectively
*   `department_id` and `department`: department identifier and name of the department, respectively
*   some variables related to the `order`, such as:
    *   `order_id`: order identifier
    *   `add_to_cart_order`: sequence of each product being added into cart in each order
    *   `order_number`: order sequence for each unique user
    *   `order_dow` and `order_hour_of_day`: time that the order was placed on
    *   `days_since_prior_order`: days since the last order

To give an illustrative example of the order NO.1 in this dataset:

```{r}
instacart %>% 
  filter(order_id == 1)
```

In the "train" evaluation set, the user 112108 ordered 8 products from dairy eggs, produce, and canned goods department in this order, including Bulgarian Yogurt, Organic 4% Milk Fat Whole Milk Cottage Cheese, Organic Celery Hearts, Cucumber Kirby, Lightly Smoked Sardines in Olive Oil, Bag of Organic Bananas, Organic Hass Avocado, and Organic Whole String Cheese. The user 112108 placed this order on Wednesday, 10 am, and this order is the 4th one for this user. The prior order of the user 112108 was placed 9 days ago.


## Some Questions Related to `instacart`

*   How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarise(
    order_count = n()
  ) %>% 
  arrange(desc(order_count)) %>% 
  head(2)
```

There are `r n_distinct(instacart$aisle)` unique aisles, and the most items are ordered from aisle "fresh vegetables", followed by aisle "fresh fruits".

*   Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r, fig.height = 6, out.width = "90%"}
instacart %>% 
  group_by(aisle) %>% 
  summarise(
    order_count = n()
  ) %>% 
  filter(order_count > 10000) %>% 
  ggplot(aes(x = reorder(aisle, desc(order_count)), y = order_count)) +
  geom_col() +
  labs(
      x = "Aisle",
      y = "Number of Items Ordered\nin Each Aisle",
      title = "Figure 1: Frequency of Items Ordered in Each Aisle",
      caption = "Data are limited to aisles with more than 10,000 items ordered."
    ) +
  theme_bw() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 90),
    plot.title = element_text(hjust = 0.5)
    )
```

The plot above shows the number of items ordered in each aisle, with data limited to aisles with more than 10000 items ordered. We can tell that the most items are ordered from aisle "fresh vegetables", followed by aisle "fresh fruits".

*   Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
    ) %>% 
  group_by(product_name) %>% 
  mutate(
    times = n()
  ) %>% 
  relocate(aisle) %>% 
  arrange(aisle, desc(times)) %>% 
  distinct(aisle, product_name, times) %>%
  group_by(aisle) %>% 
  top_n(n = 3)
```

The table above shows the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

Of the aisle "baking ingredients", the most popular item is Light Brown Sugar, followed by Pure Baking Soda and Cane Sugar. Of the aisle "dog food care", the most popular item is Snack Sticks Chicken & Rice Recipe Dog Treats, followed by Organix Chicken & Brown Rice Recipe and Small Dog Biscuits. Of the aisle "packaged vegetables fruits", the most popular item is Organic Baby Spinach, followed by Organic Raspberries and Organic Blueberries. 

*   Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart %>% 
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
    ) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(
    mean_hour = mean(order_hour_of_day, na.rm = TRUE)
  ) %>% 
  mutate(
    order_dow = ifelse(order_dow == 0, order_dow + 7, order_dow),
    order_dow = lubridate::wday(order_dow, label = TRUE, abbr = FALSE)
  ) %>%
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  )
```

The table above shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. To give an illustrative example, the mean hour of Pink Lady Apples being ordered on Saturday is 13.4.


# Problem 2

## Load, tidy, and wrangle the data

The following code chunk is to tidy the data by `pivot_longer()`, create a new variable called `weekday_vs_weekend` to indicate whether the day is weekday or weekend, and finally encode some variables (`day` and `minute`) into more reasonable classes. The resulting tidied dataset is arranged by `week` and `day`.

```{r}
accelerometer = read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity_counts",
    names_prefix = "activity_"
  ) %>% 
  mutate(
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
    weekday_vs_weekend = ifelse(day %in%  c("Saturday", "Sunday"), "weekend", "weekday"),
    minute = as.numeric(minute)
  ) %>% 
  arrange(week, day)
```

The resulting dataset includes `r nrow(accelerometer)` observations with `r ncol(accelerometer)` variables, primarily recording some activity information of a 63 year-old male with BMI 25, collected by the accelerometer. Some key variables are `activity_counts`, indicating the activity counts for each minute; `week`, `day`, `minute`, showing the time of which the data point is collected; and `weekday_vs_weekend` is a binary indicator of either weekday or weekend.

## Traditional analyses of `accelerometer`

The following code chunk creates a new variable `total_counts` by aggregating across minutes to identify the total activity for each day. The table below shows the total activities by `week` and `day`.

```{r}
accelerometer = accelerometer %>% 
  group_by(day_id) %>% 
  mutate(
    total_counts = sum(activity_counts, na.rm = TRUE)
  )

accelerometer %>% 
  distinct(week, day, total_counts) %>% 
  print.data.frame()
```

To examine any apparent trends of total activity, we'd like to make a scatterplot with a trend line added.

```{r, fig.height = 6, out.width = "90%"}
accelerometer %>% 
  ggplot(aes(x = day_id, y = total_counts, color = weekday_vs_weekend)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(
    x = "Day ID",
    y = "Total Activity Counts",
    title = "Figure 2: Total Activity Counts by Day ID",
    caption = "Day ID is the originally assigned ID by the accelerometer."    
  ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    legend.title = element_blank()
  )
```

As the above figure shows, the total activity counts on weekdays seem to be more stable, while there are more fluctuations (larger variances) on weekends. However, we should note that there are several days with total activity counts as low as 1440 (with every minute only counting "1"), indicating that the accelerometer might fail to accurately record the data.

